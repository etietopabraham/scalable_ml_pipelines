{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Trials in Modularized Production Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/macbookpro/Documents/sclable_ml_pipelines/scalable_ml_pipelines'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from us_used_cars_ml_pipeline.constants import *\n",
    "from us_used_cars_ml_pipeline.utils.common import read_yaml\n",
    "from us_used_cars_ml_pipeline import logger\n",
    "from us_used_cars_ml_pipeline.entity.config_entity import (DataIngestionConfig, \n",
    "                                                           CleanDataConfig)\n",
    "\n",
    "class ConfigurationManager:\n",
    "    \"\"\"\n",
    "    The ConfigurationManager class is responsible for reading and providing \n",
    "    configuration settings needed for various stages of the data pipeline.\n",
    "\n",
    "    Attributes:\n",
    "    - config (dict): Dictionary holding configuration settings from the config file.\n",
    "    - params (dict): Dictionary holding parameter values from the params file.\n",
    "    - schema (dict): Dictionary holding schema information from the schema file.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 config_filepath=CONFIG_FILE_PATH, \n",
    "                 params_filepath=PARAMS_FILE_PATH, \n",
    "                 schema_filepath=SCHEMA_FILE_PATH):\n",
    "        \"\"\"\n",
    "        Initializes the ConfigurationManager with configurations, parameters, and schema.\n",
    "\n",
    "        Parameters:\n",
    "        - config_filepath (str): Filepath to the configuration file.\n",
    "        - params_filepath (str): Filepath to the parameters file.\n",
    "        - schema_filepath (str): Filepath to the schema file.\n",
    "        \"\"\"\n",
    "        self.config = self._read_config_file(config_filepath, \"config\")\n",
    "        self.params = self._read_config_file(params_filepath, \"params\")\n",
    "        self.schema = self._read_config_file(schema_filepath, \"schema\")\n",
    "\n",
    "    def _read_config_file(self, filepath: str, config_name: str) -> dict:\n",
    "        \"\"\"\n",
    "        Reads and returns the content of a configuration file.\n",
    "\n",
    "        Parameters:\n",
    "        - filepath (str): The file path to the configuration file.\n",
    "        - config_name (str): Name of the configuration (used for logging purposes).\n",
    "\n",
    "        Returns:\n",
    "        - dict: Dictionary containing the configuration settings.\n",
    "\n",
    "        Raises:\n",
    "        - Exception: An error occurred reading the configuration file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return read_yaml(filepath)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading {config_name} file: {filepath}. Error: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        \"\"\"\n",
    "        Extracts and returns data ingestion configuration settings as a DataIngestionConfig object.\n",
    "\n",
    "        Returns:\n",
    "        - DataIngestionConfig: Object containing data ingestion configuration settings.\n",
    "\n",
    "        Raises:\n",
    "        - AttributeError: The 'data_ingestion' attribute does not exist in the config file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            config = self.config.data_ingestion\n",
    "            return DataIngestionConfig(\n",
    "                root_dir=config.root_dir,\n",
    "                source_URL=config.source_URL,\n",
    "                hdfs_data_file=config.hdfs_data_file\n",
    "            )\n",
    "        except AttributeError as e:\n",
    "            logger.error(\"The 'data_ingestion' attribute does not exist in the config file.\")\n",
    "            raise e\n",
    "\n",
    "    def get_clean_data_config(self) -> CleanDataConfig:\n",
    "        \"\"\"\n",
    "        Extracts and returns data cleaning configuration settings as a CleanDataConfig object.\n",
    "\n",
    "        Returns:\n",
    "        - CleanDataConfig: Object containing data cleaning configuration settings.\n",
    "\n",
    "        Raises:\n",
    "        - AttributeError: The 'clean_data' attribute does not exist in the config file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            config = self.config.clean_data\n",
    "            return CleanDataConfig(\n",
    "                root_dir=config.root_dir,\n",
    "                hdfs_data_file=config.hdfs_data_file,\n",
    "                clean_data_URL=config.clean_data_URL\n",
    "            )\n",
    "        except AttributeError as e:\n",
    "            logger.error(\"The 'clean_data' attribute does not exist in the config file.\")\n",
    "            raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from us_used_cars_ml_pipeline.entity.config_entity import CleanDataConfig\n",
    "from us_used_cars_ml_pipeline import logger\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType, FloatType, BooleanType, DateType, DoubleType, StringType\n",
    "\n",
    "\n",
    "class CleanData:\n",
    "    \"\"\"\n",
    "    Class for cleaning the used cars dataset.\n",
    "\n",
    "    Attributes:\n",
    "    - config (CleanDataConfig): Configuration for the data cleaning process.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: CleanDataConfig):\n",
    "        \"\"\"\n",
    "        Initializes the CleanData object with the given configuration.\n",
    "\n",
    "        Parameters:\n",
    "        - config (CleanDataConfig): Configuration for the data cleaning process.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "\n",
    "    def read_data_from_hdfs(self, spark: SparkSession) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Reads the data from HDFS using the provided SparkSession.\n",
    "\n",
    "        Parameters:\n",
    "        - spark (SparkSession): SparkSession object.\n",
    "\n",
    "        Returns:\n",
    "        - DataFrame: Spark DataFrame containing the read data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df = spark.read.csv(self.config.hdfs_data_file, header=True, inferSchema=True)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to read data from HDFS. Error: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def to_float(self, col):\n",
    "        \"\"\"\n",
    "        Utility function to extract float from strings with units.\n",
    "\n",
    "        Parameters:\n",
    "        - col (Column): Spark DataFrame column.\n",
    "\n",
    "        Returns:\n",
    "        - Column: Transformed column with float values.\n",
    "        \"\"\"\n",
    "        return F.regexp_extract(col, r\"(\\d+\\.?\\d*)\", 1).cast(FloatType())\n",
    "\n",
    "    def to_int(self, col):\n",
    "        \"\"\"\n",
    "        Utility function to extract integer from strings.\n",
    "\n",
    "        Parameters:\n",
    "        - col (Column): Spark DataFrame column.\n",
    "\n",
    "        Returns:\n",
    "        - Column: Transformed column with integer values.\n",
    "        \"\"\"\n",
    "        return F.regexp_extract(col, r\"(\\d+)\", 1).cast(IntegerType())\n",
    "\n",
    "    def to_bool(self, col):\n",
    "        \"\"\"\n",
    "        Utility function to convert to boolean.\n",
    "\n",
    "        Parameters:\n",
    "        - col (Column): Spark DataFrame column.\n",
    "\n",
    "        Returns:\n",
    "        - Column: Transformed column with boolean values.\n",
    "        \"\"\"\n",
    "        return col.cast(BooleanType())\n",
    "\n",
    "    def split_power_torque(self, df, col_name):\n",
    "        \"\"\"\n",
    "        Utility function to split power and torque into value and rpm.\n",
    "\n",
    "        Parameters:\n",
    "        - df (DataFrame): Spark DataFrame.\n",
    "        - col_name (str): Name of the column to split.\n",
    "\n",
    "        Returns:\n",
    "        - DataFrame: DataFrame with new columns for value and rpm.\n",
    "        \"\"\"\n",
    "        value = F.regexp_extract(df[col_name], r\"(\\d+)\", 1).cast(IntegerType())\n",
    "        rpm = F.regexp_replace(F.regexp_extract(df[col_name], r\"@ ([\\d,]+)\", 1), \",\", \"\").cast(IntegerType())\n",
    "        return df.withColumn(f\"{col_name}_value\", value).withColumn(f\"{col_name}_rpm\", rpm)\n",
    "\n",
    "    def perform_cleaning(self, df: DataFrame) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Performs cleaning operations on the input DataFrame.\n",
    "\n",
    "        Parameters:\n",
    "        - df (DataFrame): Input Spark DataFrame.\n",
    "\n",
    "        Returns:\n",
    "        - DataFrame: Cleaned DataFrame.\n",
    "        \"\"\"\n",
    "        conversion_dict = {\n",
    "            'back_legroom': self.to_float,\n",
    "            'bed_height': self.to_float,\n",
    "            'bed_length': self.to_float,\n",
    "            'front_legroom': self.to_float,\n",
    "            'height': self.to_float,\n",
    "            'length': self.to_float,\n",
    "            'wheelbase': self.to_float,\n",
    "            'width': self.to_float,\n",
    "            'city_fuel_economy': self.to_float,\n",
    "            'combine_fuel_economy': self.to_float,\n",
    "            'daysonmarket': self.to_int,\n",
    "            'engine_displacement': self.to_float,\n",
    "            'fuel_tank_volume': self.to_float,\n",
    "            'highway_fuel_economy': self.to_float,\n",
    "            'horsepower': self.to_int,\n",
    "            'latitude': self.to_float,\n",
    "            'longitude': self.to_float,\n",
    "            'mileage': self.to_float,\n",
    "            'owner_count': self.to_int,\n",
    "            'price': self.to_float,\n",
    "            'savings_amount': self.to_float,\n",
    "            'seller_rating': self.to_float,\n",
    "            'year': self.to_int,\n",
    "            'fleet': self.to_bool,\n",
    "            'frame_damaged': self.to_bool,\n",
    "            'franchise_dealer': self.to_bool,\n",
    "            'has_accidents': self.to_bool,\n",
    "            'isCab': self.to_bool,\n",
    "            'is_certified': self.to_bool,\n",
    "            'is_cpo': self.to_bool,\n",
    "            'is_new': self.to_bool,\n",
    "            'is_oemcpo': self.to_bool,\n",
    "            'salvage': self.to_bool,\n",
    "            'theft_title': self.to_bool\n",
    "        }\n",
    "\n",
    "        # Apply conversion functions to corresponding columns\n",
    "        for col, func in conversion_dict.items():\n",
    "            df = df.withColumn(col, func(df[col]))\n",
    "\n",
    "        # Convert listed_date to DateType\n",
    "        df = df.withColumn('listed_date', F.to_date(df['listed_date'], 'yyyy-MM-dd'))\n",
    "\n",
    "        # Split power and torque into value and rpm, and add new columns\n",
    "        df = self.split_power_torque(df, 'power')\n",
    "        df = self.split_power_torque(df, 'torque')\n",
    "\n",
    "        # Cleaning maximum_seating and converting to Integer\n",
    "        df = df.withColumn('maximum_seating', F.regexp_replace(F.col('maximum_seating'), '[^\\d]+', '').cast(IntegerType()))\n",
    "\n",
    "        return df  # Return cleaned DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-08 16:12:35,807: 44: us_used_cars_ml_pipeline_logger: INFO: common:  yaml file: config/config.yaml loaded successfully]\n",
      "[2023-10-08 16:12:35,813: 44: us_used_cars_ml_pipeline_logger: INFO: common:  yaml file: params.yaml loaded successfully]\n",
      "[2023-10-08 16:12:35,815: 44: us_used_cars_ml_pipeline_logger: INFO: common:  yaml file: schema.yaml loaded successfully]\n",
      "[2023-10-08 16:12:35,815: 72: us_used_cars_ml_pipeline_logger: INFO: 1060998365:  >>>>>> Stage: Data Cleaning Stage started <<<<<<]\n",
      "[2023-10-08 16:12:35,817: 43: us_used_cars_ml_pipeline_logger: INFO: 1060998365:  Fetching data cleaning configuration...]\n",
      "[2023-10-08 16:12:35,818: 46: us_used_cars_ml_pipeline_logger: INFO: 1060998365:  Initializing data cleaning process...]\n",
      "[2023-10-08 16:12:35,818: 49: us_used_cars_ml_pipeline_logger: INFO: 1060998365:  Read data for cleaning process...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/08 16:12:37 WARN Utils: Your hostname, Macbooks-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.0.100 instead (on interface en0)\n",
      "23/10/08 16:12:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/08 16:12:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/10/08 16:12:39 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "[Stage 1:========================================================>(74 + 1) / 75]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-08 16:13:22,147: 53: us_used_cars_ml_pipeline_logger: INFO: 1060998365:  Perform data cleaning]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-08 16:13:23,729: 60: us_used_cars_ml_pipeline_logger: INFO: 1060998365:  Writing cleaned data back to HDFS at hdfs://localhost:9000/geekradius/used_cars_project/clean_data]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/08 16:13:23 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "23/10/08 16:13:26 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:13:26 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:13:48 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:13:49 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:13:49 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:13:50 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:13:50 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:13:50 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:14:11 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:14:11 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:14:11 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:14:12 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:14:12 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:14:13 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:14:14 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:14:14 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:14:15 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:14:15 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:14:15 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:14:16 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:14:16 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:14:31 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:14:31 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:14:31 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:14:31 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:14:32 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:14:32 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:14:34 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:14:34 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:14:35 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:14:38 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:14:39 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:14:40 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:14:40 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:14:41 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:14:46 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:15:17 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:15:18 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:15:18 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:15:18 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:15:18 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:15:21 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:15:21 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:15:45 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:15:50 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:15:50 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:16:09 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:16:10 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:16:10 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:16:11 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:16:11 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:16:11 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:16:12 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:16:12 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:16:37 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:16:37 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:16:39 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:16:39 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:16:40 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:16:40 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:16:41 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:16:41 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:16:41 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:16:41 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:16:41 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:16:55 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:16:55 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:17:16 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:17:16 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:17:16 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:17:17 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:17:17 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:17:17 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:17:19 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:17:19 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:17:54 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:17:55 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "23/10/08 16:17:55 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "23/10/08 16:17:55 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-08 16:18:09,151: 74: us_used_cars_ml_pipeline_logger: INFO: 1060998365:  >>>>>> Stage Data Cleaning Stage completed <<<<<< \n",
      "\n",
      "x==========x]\n"
     ]
    }
   ],
   "source": [
    "# from us_used_cars_ml_pipeline.config.configuration import ConfigurationManager from config\n",
    "from pyspark.sql import SparkSession\n",
    "from us_used_cars_ml_pipeline.components.data_cleaning import CleanData\n",
    "from us_used_cars_ml_pipeline import logger\n",
    "from us_used_cars_ml_pipeline.utils.common import get_spark_session\n",
    "\n",
    "class DataCleaningPipeline:\n",
    "    \"\"\"\n",
    "    Pipeline for cleaning the used cars dataset.\n",
    "\n",
    "    Class Attributes:\n",
    "    - STAGE_NAME (str): Stage name for logging purposes.\n",
    "\n",
    "    Attributes:\n",
    "    - config_manager (ConfigurationManager): Manager for configuration settings.\n",
    "    \"\"\"\n",
    "    \n",
    "    STAGE_NAME = \"Data Cleaning Stage\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the DataCleaningPipeline object with the ConfigurationManager.\n",
    "        \"\"\"\n",
    "        self.config_manager = ConfigurationManager()\n",
    "\n",
    "    def initialize_spark_session(self) -> SparkSession:\n",
    "        \"\"\"\n",
    "        Initializes and returns a Spark session.\n",
    "        \n",
    "        Returns:\n",
    "        - SparkSession: Initialized Spark session.\n",
    "        \"\"\"\n",
    "        return get_spark_session()\n",
    "\n",
    "    def run_data_cleaning(self):\n",
    "        \"\"\"\n",
    "        Runs the data cleaning process.\n",
    "        \n",
    "        This method fetches the data cleaning configuration, initializes the data cleaning process,\n",
    "        reads the data, and performs data cleaning using the CleanData component.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"Fetching data cleaning configuration...\")\n",
    "            data_cleaning_configuration = self.config_manager.get_clean_data_config()\n",
    "            \n",
    "            logger.info(\"Initializing data cleaning process...\")\n",
    "            data_cleaning = CleanData(config=data_cleaning_configuration)\n",
    "\n",
    "            logger.info(\"Read data for cleaning process...\")\n",
    "            spark = self.initialize_spark_session()\n",
    "            df = data_cleaning.read_data_from_hdfs(spark)\n",
    "\n",
    "            logger.info(\"Perform data cleaning\")\n",
    "            cleaned_df = data_cleaning.perform_cleaning(df)\n",
    "            \n",
    "            hdfs_path = data_cleaning_configuration.clean_data_URL\n",
    "            if not hdfs_path:  # or any other validation check you find appropriate\n",
    "                logger.error(\"Invalid HDFS path in configuration. Aborting data cleaning process.\")\n",
    "                raise ValueError(\"Invalid HDFS path in configuration.\")\n",
    "            logger.info(f\"Writing cleaned data back to HDFS at {hdfs_path}\")\n",
    "            cleaned_df.write.mode('overwrite').parquet(hdfs_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.exception(\"An error occurred during the data cleaning process.\")\n",
    "            raise e\n",
    "        \n",
    "    def run_pipeline(self):\n",
    "        \"\"\"\n",
    "        Runs the Data Cleaning Pipeline, logging the start and completion of the stage.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(f\">>>>>> Stage: {DataCleaningPipeline.STAGE_NAME} started <<<<<<\")\n",
    "            self.run_data_cleaning()\n",
    "            logger.info(f\">>>>>> Stage {DataCleaningPipeline.STAGE_NAME} completed <<<<<< \\n\\nx==========x\")\n",
    "        except Exception as e:\n",
    "            # No need to log the exception here since it's already logged in the run_data_cleaning method.\n",
    "            raise e\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pipeline = DataCleaningPipeline()\n",
    "    pipeline.run_pipeline()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "us_used_cars_ml_pipeline_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
